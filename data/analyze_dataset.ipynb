{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99799459",
   "metadata": {},
   "source": [
    "Analysis of CDC w.r.t. dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f251716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from conformal_data_cleaning.cleaner.autogluon import ConformalAutoGluonCleaner\n",
    "\n",
    "def is_categorical(\n",
    "    column: pd.Series,\n",
    "    n_samples: int = 1000,\n",
    "    max_unique_fraction: float = 0.2,\n",
    "    random_generator: None = None,\n",
    ") -> bool:\n",
    "    \"\"\"Check if `column` type is categorical.\n",
    "\n",
    "    A heuristic to check whether a `column` is categorical:\n",
    "    a column is considered categorical (as opposed to a plain text column)\n",
    "    if the relative cardinality is `max_unique_fraction` or less.\n",
    "\n",
    "    Args:\n",
    "        column (ArrayLike): pandas `Series` containing strings\n",
    "        n_samples (int, optional): number of samples used for heuristic. Defaults to 1000.\n",
    "        max_unique_fraction (float, optional): maximum relative cardinality. Defaults to 0.2.\n",
    "        random_generator (Generator, optional): random generator. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        bool: `True` if the column is categorical according to the heuristic.\n",
    "    \"\"\"\n",
    "    if random_generator is None:\n",
    "        random_generator = np.random.default_rng()\n",
    "\n",
    "    column = np.array(column)\n",
    "    n_samples = min(n_samples, len(column))\n",
    "    values, counts = np.unique(column, return_counts=True)\n",
    "    sample = random_generator.choice(a=values, p=counts / counts.sum(), size=n_samples)\n",
    "    unique_samples = np.unique(sample)\n",
    "\n",
    "    return unique_samples.shape[0] / n_samples <= max_unique_fraction\n",
    "\n",
    "\n",
    "def conformal_clean(\n",
    "    test_df: pd.DataFrame,\n",
    "    train_df: pd.DataFrame,\n",
    "    c_level: float,\n",
    "    njobs: int = 4,\n",
    "    seed:int = 41\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Input: \n",
    "        the perturbed dataframe given in the demo\n",
    "        the alpha value for conformal coverage\n",
    "\n",
    "\n",
    "    Output:\n",
    "        Cleaned dataframe\n",
    "    \"\"\"\n",
    "    model_hps = {\"hyperparameters\": {\"RF\": {}}}\n",
    "    cleaner: ConformalAutoGluonCleaner = ConformalAutoGluonCleaner(confidence_level=c_level, seed = seed)\n",
    "    fit_cleaner = cleaner.fit(train_df, ci_ag_fit_params=model_hps)\n",
    "    cleaned_test_df, cleaned_mask = fit_cleaner.transform(test_df)\n",
    "\n",
    "    # Analysis\n",
    "    coverages = []\n",
    "    empty_set_fractions = []\n",
    "    average_set_sizes = []\n",
    "    relative_average_set_sizes = []\n",
    "\n",
    "    # Get categorical and numerical columns\n",
    "    categorical_cols = [c for c in train_df.columns if is_categorical(train_df[c])]\n",
    "    numerical_cols = [c for c in train_df.columns if not is_categorical(train_df[c])]\n",
    "\n",
    "    for column_name, prediction_sets in cleaner._prediction_sets.items():\n",
    "        if column_name in categorical_cols:\n",
    "            cardinality = len(train_df[column_name].unique())\n",
    "            true_value_in_prediction_set = np.any(\n",
    "                prediction_sets == test_df[column_name].to_numpy()[:, np.newaxis], axis=1\n",
    "            )\n",
    "            coverages.append(true_value_in_prediction_set.mean())\n",
    "\n",
    "            average_set_sizes.append((~pd.DataFrame(prediction_sets).isna()).sum(axis=1).mean())\n",
    "            relative_average_set_sizes.append(average_set_sizes[-1] / cardinality)\n",
    "            empty_set_fractions.append(((~pd.DataFrame(prediction_sets).isna()).sum(axis=1) == 0).mean())\n",
    "\n",
    "        elif column_name in numerical_cols:\n",
    "            value_range = (\n",
    "                train_df[column_name].max()\n",
    "                - train_df[column_name].min()\n",
    "            )\n",
    "            true_value_in_prediction_range = (test_df[column_name].to_numpy() >= prediction_sets[:, 0]) & (\n",
    "                test_df[column_name].to_numpy() <= prediction_sets[:, 1]\n",
    "            )\n",
    "            coverages.append(true_value_in_prediction_range.mean())\n",
    "            average_set_sizes.append((prediction_sets[:, 1] - prediction_sets[:, 0]).mean())\n",
    "            relative_average_set_sizes.append(average_set_sizes[-1] / value_range)\n",
    "            empty_set_fractions.append(((prediction_sets[:, 1] - prediction_sets[:, 0]) == 0).mean())\n",
    "\n",
    "\n",
    "    return cleaned_test_df, cleaned_mask, coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c066931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"44969.csv\")\n",
    "\n",
    "y = np.ones(len(df))\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6e40d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:27:22,680 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:27:22,680 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.52 GB / 11.46 GB (30.7%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3607.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.5 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16410.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:27:23,778 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:27:23,778 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.53 GB / 11.46 GB (30.8%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3616.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.5 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.9s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16184.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:27:24,876 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:27:24,876 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.54 GB / 11.46 GB (30.9%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3605.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.817\t = Validation score   (-pinball_loss)\n",
      "\t3.03s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.817\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.96s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1932.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:27:29,719 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:27:29,719 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.44 GB / 11.46 GB (30.0%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3534.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0239\t = Validation score   (-pinball_loss)\n",
      "\t2.98s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0239\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.72s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2415.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:27:34,246 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:27:34,246 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.47 GB / 11.46 GB (30.3%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3553.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.3539\t = Validation score   (-pinball_loss)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.3539\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.71s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2214.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:27:38,859 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:27:38,859 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.62 GB / 11.46 GB (31.6%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3715.70 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0009\t = Validation score   (-pinball_loss)\n",
      "\t2.95s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0009\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.58s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2317.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:27:43,337 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:27:43,337 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.33 GB / 11.46 GB (29.1%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3472.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0008\t = Validation score   (-pinball_loss)\n",
      "\t2.86s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0008\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.53s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2098.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:27:47,703 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:27:47,703 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.49 GB / 11.46 GB (30.5%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3574.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.1501\t = Validation score   (-pinball_loss)\n",
      "\t2.97s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.1501\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.9s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2162.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:27:52,580 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:27:52,580 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.69 GB / 11.46 GB (32.2%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3780.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.056\t = Validation score   (-pinball_loss)\n",
      "\t3.0s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.056\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.9s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2227.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:27:57,443 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:27:57,443 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.74 GB / 11.46 GB (32.7%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3829.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t2.95s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.91s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1332.6 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:28:03,332 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:28:03,332 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.68 GB / 11.46 GB (32.1%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3767.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0023\t = Validation score   (-pinball_loss)\n",
      "\t3.78s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0023\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.63s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2289.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:28:08,900 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:28:08,900 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.65 GB / 11.46 GB (31.9%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9988215267775304\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3740.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6865, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/3.6 GB\n",
      "\t0.9879\t = Validation score   (f1_macro)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9879\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16146.5 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:28:10,208 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:28:10,208 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.67 GB / 11.46 GB (32.1%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3762.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0181\t = Validation score   (-pinball_loss)\n",
      "\t4.01s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0181\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.63s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1394.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:28:18,026 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:28:18,026 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.68 GB / 11.46 GB (32.1%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3776.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.55s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1884.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:28:22,930 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:28:22,930 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.72 GB / 11.46 GB (32.5%)\n",
      "Disk Space Avail:   96.18 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3809.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 202 due to low memory. Expected memory usage reduced from 22.21% -> 15.0% of available memory...\n",
      "\t0.1383\t = Validation score   (f1_macro)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.1383\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.82s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16335.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:28:43,463 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:28:43,463 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.74 GB / 11.46 GB (32.6%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3815.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.7 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16467.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:28:44,531 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:28:44,531 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.69 GB / 11.46 GB (32.2%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3777.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.7 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16586.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:28:45,608 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:28:45,608 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.67 GB / 11.46 GB (32.1%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3761.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.2723\t = Validation score   (-pinball_loss)\n",
      "\t4.33s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.2723\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1977.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:28:52,106 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:28:52,106 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.47 GB / 11.46 GB (30.3%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3548.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0214\t = Validation score   (-pinball_loss)\n",
      "\t4.09s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0214\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.01s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2058.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:28:58,105 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:28:58,105 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.55 GB / 11.46 GB (31.0%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3632.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.2471\t = Validation score   (-pinball_loss)\n",
      "\t3.74s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.2471\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.57s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2262.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:29:03,633 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:29:03,633 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.64 GB / 11.46 GB (31.8%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3727.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0005\t = Validation score   (-pinball_loss)\n",
      "\t3.67s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0005\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2166.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:29:08,846 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:29:08,846 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.68 GB / 11.46 GB (32.1%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3764.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0005\t = Validation score   (-pinball_loss)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0005\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.4s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2260.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:29:14,119 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:29:14,119 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.70 GB / 11.46 GB (32.3%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3783.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.1136\t = Validation score   (-pinball_loss)\n",
      "\t3.92s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.1136\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2194.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:29:19,927 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:29:19,927 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.71 GB / 11.46 GB (32.3%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3794.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0391\t = Validation score   (-pinball_loss)\n",
      "\t3.91s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0391\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.79s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2238.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:29:25,576 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:29:25,576 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.80 GB / 11.46 GB (33.1%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3880.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.39s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.35s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1467.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:29:31,820 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:29:31,820 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.71 GB / 11.46 GB (32.4%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3796.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0016\t = Validation score   (-pinball_loss)\n",
      "\t4.04s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0016\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.85s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2291.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:29:38,481 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:29:38,481 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.73 GB / 11.46 GB (32.5%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9985596438392039\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3817.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6863, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/3.7 GB\n",
      "\t0.9893\t = Validation score   (f1_macro)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9893\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.39s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11044.9 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:29:40,099 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:29:40,099 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.69 GB / 11.46 GB (32.2%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3779.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0147\t = Validation score   (-pinball_loss)\n",
      "\t4.71s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0147\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1389.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:29:48,231 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:29:48,231 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.79 GB / 11.46 GB (33.0%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3871.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.73s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.66s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1459.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:29:54,322 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:29:54,322 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.70 GB / 11.46 GB (32.3%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3783.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/3.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 202 due to low memory. Expected memory usage reduced from 22.2% -> 15.0% of available memory...\n",
      "\t0.163\t = Validation score   (f1_macro)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.163\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13432.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:30:16,628 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:30:16,628 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.82 GB / 11.46 GB (33.3%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3901.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.05s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 12942.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:30:17,920 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:30:17,920 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.79 GB / 11.46 GB (33.1%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3879.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.15s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11044.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:30:19,347 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:30:19,347 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.75 GB / 11.46 GB (32.8%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3843.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.2645\t = Validation score   (-pinball_loss)\n",
      "\t4.86s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.2645\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1972.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:30:26,256 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:30:26,256 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.71 GB / 11.46 GB (32.4%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3792.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.018\t = Validation score   (-pinball_loss)\n",
      "\t4.77s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.018\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.15s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1991.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:30:38,226 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:30:38,226 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.79 GB / 11.46 GB (33.1%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3881.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.23\t = Validation score   (-pinball_loss)\n",
      "\t3.65s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.23\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1911.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:30:50,750 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:30:50,750 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.72 GB / 11.46 GB (32.5%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3804.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t3.2s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1990.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:31:01,464 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:31:01,464 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.74 GB / 11.46 GB (32.7%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3827.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.75s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1982.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:31:14,115 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:31:14,115 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.74 GB / 11.46 GB (32.7%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3831.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0866\t = Validation score   (-pinball_loss)\n",
      "\t3.37s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0866\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.59s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1943.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:31:24,578 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:31:24,578 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.69 GB / 11.46 GB (32.2%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3780.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0344\t = Validation score   (-pinball_loss)\n",
      "\t4.0s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0344\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.93s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1998.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:31:30,526 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:31:30,526 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.70 GB / 11.46 GB (32.3%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3789.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t4.3s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.47s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1003.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:31:37,807 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:31:37,807 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.68 GB / 11.46 GB (32.1%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3763.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0013\t = Validation score   (-pinball_loss)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0013\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1810.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:31:44,905 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:31:44,905 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.62 GB / 11.46 GB (31.6%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9986905853083672\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3711.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6864, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/3.6 GB\n",
      "\t0.9747\t = Validation score   (f1_macro)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9747\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.47s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9293.4 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:31:46,652 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:31:46,652 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.60 GB / 11.46 GB (31.5%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3690.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0099\t = Validation score   (-pinball_loss)\n",
      "\t5.13s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0099\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.33s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1322.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:31:55,816 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:31:55,816 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.67 GB / 11.46 GB (32.0%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3749.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.99s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1382.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:32:02,379 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:32:02,379 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.64 GB / 11.46 GB (31.7%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3721.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 196 due to low memory. Expected memory usage reduced from 22.88% -> 15.0% of available memory...\n",
      "\t0.1417\t = Validation score   (f1_macro)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.1417\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13348.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:32:23,923 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:32:23,923 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.77 GB / 11.46 GB (32.9%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3844.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.7 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.16s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13446.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:32:25,347 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:32:25,347 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.68 GB / 11.46 GB (32.1%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3766.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.7 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.29s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10769.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:32:26,946 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:32:26,946 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.66 GB / 11.46 GB (32.0%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3751.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.8303\t = Validation score   (-pinball_loss)\n",
      "\t4.98s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.8303\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.02s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1948.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:32:34,063 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:32:34,063 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.70 GB / 11.46 GB (32.3%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3781.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0266\t = Validation score   (-pinball_loss)\n",
      "\t5.05s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0266\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.95s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1934.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:32:41,108 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:32:41,108 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.72 GB / 11.46 GB (32.5%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3801.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.374\t = Validation score   (-pinball_loss)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.374\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.91s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2051.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:32:48,020 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:32:48,020 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.69 GB / 11.46 GB (32.2%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3781.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.001\t = Validation score   (-pinball_loss)\n",
      "\t4.52s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.16s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2051.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:32:54,245 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:32:54,245 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.65 GB / 11.46 GB (31.9%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3703.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0008\t = Validation score   (-pinball_loss)\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0008\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.04s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1465.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:33:01,329 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:33:01,329 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.48 GB / 11.46 GB (30.4%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3563.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.1574\t = Validation score   (-pinball_loss)\n",
      "\t5.34s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.1574\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.33s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1922.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:33:08,731 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:33:08,731 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.51 GB / 11.46 GB (30.6%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3592.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.055\t = Validation score   (-pinball_loss)\n",
      "\t4.91s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.055\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.88s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1886.6 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:33:15,607 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:33:15,607 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.58 GB / 11.46 GB (31.2%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3661.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t4.1s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.35s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 982.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:33:22,961 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:33:22,961 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.55 GB / 11.46 GB (31.0%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3629.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0022\t = Validation score   (-pinball_loss)\n",
      "\t5.1s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0022\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.07s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1884.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:33:30,129 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:33:30,129 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.36 GB / 11.46 GB (29.3%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9985596438392039\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3441.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6863, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/3.4 GB\n",
      "\t0.9827\t = Validation score   (f1_macro)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9827\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10658.0 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:33:31,896 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:33:31,896 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.46 GB / 11.46 GB (30.2%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3541.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0202\t = Validation score   (-pinball_loss)\n",
      "\t4.84s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0202\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.15s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1150.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:33:40,793 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:33:40,793 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.60 GB / 11.46 GB (31.4%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3686.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.89s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.8s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1548.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:33:47,448 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:33:47,448 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.60 GB / 11.46 GB (31.4%)\n",
      "Disk Space Avail:   96.11 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3687.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/3.6 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 193 due to low memory. Expected memory usage reduced from 23.26% -> 15.0% of available memory...\n",
      "\t0.1491\t = Validation score   (f1_macro)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.1491\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13063.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:34:13,779 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:34:13,779 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.16 GB / 11.46 GB (27.6%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3195.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.1 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.28s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11099.6 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:34:15,361 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:34:15,361 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.09 GB / 11.46 GB (26.9%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3160.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.39s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/3.1 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.33s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11078.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:34:17,138 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:34:17,138 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.04 GB / 11.46 GB (26.5%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3107.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.4148\t = Validation score   (-pinball_loss)\n",
      "\t5.4s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.4148\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.67s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1709.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:34:25,000 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:34:25,000 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.18 GB / 11.46 GB (27.8%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3255.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0181\t = Validation score   (-pinball_loss)\n",
      "\t5.56s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0181\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.59s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1548.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:34:32,984 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:34:32,984 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.10 GB / 11.46 GB (27.0%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3171.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.2768\t = Validation score   (-pinball_loss)\n",
      "\t5.02s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.2768\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.06s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1933.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:34:40,148 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:34:40,148 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.15 GB / 11.46 GB (27.5%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3221.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t4.5s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.38s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1483.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:34:46,587 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:34:46,587 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.25 GB / 11.46 GB (28.4%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3315.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0006\t = Validation score   (-pinball_loss)\n",
      "\t4.59s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0006\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1944.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:34:52,953 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:34:52,953 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.26 GB / 11.46 GB (28.4%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3338.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0956\t = Validation score   (-pinball_loss)\n",
      "\t4.67s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0956\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2069.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:35:00,330 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:35:00,330 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.24 GB / 11.46 GB (28.3%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3319.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0389\t = Validation score   (-pinball_loss)\n",
      "\t5.14s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0389\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.2s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1842.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:35:07,783 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:35:07,783 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.24 GB / 11.46 GB (28.2%)\n",
      "Disk Space Avail:   96.10 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3310.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.45s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t5.93s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 552.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:35:22,779 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:35:22,779 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.64 GB / 11.46 GB (23.0%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2689.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.41s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0014\t = Validation score   (-pinball_loss)\n",
      "\t5.56s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0014\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.19s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1525.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:35:37,992 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:35:37,992 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.71 GB / 11.46 GB (23.7%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.999083409715857\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2775.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6867, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/2.7 GB\n",
      "\t0.9903\t = Validation score   (f1_macro)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9903\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.95s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16475.1 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:35:40,154 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:35:40,154 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.70 GB / 11.46 GB (23.6%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2761.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0111\t = Validation score   (-pinball_loss)\n",
      "\t6.41s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0111\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 18.62s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 652.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:36:01,335 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:36:01,335 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.72 GB / 11.46 GB (23.7%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2775.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1619.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:36:07,673 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:36:07,673 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.76 GB / 11.46 GB (24.1%)\n",
      "Disk Space Avail:   96.09 GB / 467.89 GB (20.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2825.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/2.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 149 due to low memory. Expected memory usage reduced from 30.16% -> 15.0% of available memory...\n",
      "\t0.1425\t = Validation score   (f1_macro)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.1425\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.57s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16206.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:36:28,005 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:36:28,005 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.85 GB / 11.46 GB (24.8%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2896.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11196.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:36:29,510 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:36:29,510 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.82 GB / 11.46 GB (24.6%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2886.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11172.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:36:31,083 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:36:31,083 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.82 GB / 11.46 GB (24.6%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2892.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.2323\t = Validation score   (-pinball_loss)\n",
      "\t5.23s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.2323\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.25s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2083.6 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:36:38,383 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:36:38,383 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.72 GB / 11.46 GB (23.8%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2785.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0219\t = Validation score   (-pinball_loss)\n",
      "\t4.81s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0219\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.72s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2033.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:36:45,235 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:36:45,235 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.80 GB / 11.46 GB (24.5%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2869.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.2571\t = Validation score   (-pinball_loss)\n",
      "\t4.73s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.2571\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.74s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2045.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:36:52,030 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:36:52,030 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.81 GB / 11.46 GB (24.5%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2876.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t4.78s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.5s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1922.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:36:58,555 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:36:58,555 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.83 GB / 11.46 GB (24.7%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2887.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t4.61s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.27s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2036.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:37:04,980 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:37:04,980 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.74 GB / 11.46 GB (23.9%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2715.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.4s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0959\t = Validation score   (-pinball_loss)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0959\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1942.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:37:12,418 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:37:12,418 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.58 GB / 11.46 GB (22.5%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2632.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.035\t = Validation score   (-pinball_loss)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.035\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.87s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2051.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:37:19,407 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:37:19,407 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.73 GB / 11.46 GB (23.8%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2801.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t4.0s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1167.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:37:26,897 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:37:26,897 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.70 GB / 11.46 GB (23.6%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2759.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0014\t = Validation score   (-pinball_loss)\n",
      "\t4.53s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0014\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.44s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2396.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:37:33,326 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:37:33,326 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.71 GB / 11.46 GB (23.7%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9986905853083672\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2775.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6864, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/2.7 GB\n",
      "\t0.9825\t = Validation score   (f1_macro)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9825\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.59s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6250.5 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:37:35,295 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:37:35,295 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.69 GB / 11.46 GB (23.4%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2756.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0106\t = Validation score   (-pinball_loss)\n",
      "\t5.19s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0106\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.39s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1350.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:37:44,471 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:37:44,471 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.80 GB / 11.46 GB (24.5%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2863.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.95s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.87s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1622.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:37:50,947 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:37:50,947 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.80 GB / 11.46 GB (24.4%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2861.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/2.8 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 151 due to low memory. Expected memory usage reduced from 29.65% -> 15.0% of available memory...\n",
      "\t0.163\t = Validation score   (f1_macro)\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.163\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.49s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16139.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:38:11,020 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:38:11,020 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.87 GB / 11.46 GB (25.0%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2926.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13505.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:38:12,509 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:38:12,509 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.82 GB / 11.46 GB (24.6%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2894.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.25s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13372.6 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:38:14,036 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:38:14,036 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.81 GB / 11.46 GB (24.5%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2879.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-2.3969\t = Validation score   (-pinball_loss)\n",
      "\t4.86s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-2.3969\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.98s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2026.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:38:21,111 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:38:21,111 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.88 GB / 11.46 GB (25.1%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2943.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.024\t = Validation score   (-pinball_loss)\n",
      "\t4.79s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.024\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.72s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2102.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:38:27,938 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:38:27,938 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.87 GB / 11.46 GB (25.0%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2933.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.4154\t = Validation score   (-pinball_loss)\n",
      "\t5.07s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.4154\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1662.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:38:35,139 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:38:35,139 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.84 GB / 11.46 GB (24.8%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2902.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0007\t = Validation score   (-pinball_loss)\n",
      "\t6.14s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0007\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.79s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2011.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:38:43,136 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:38:43,136 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.66 GB / 11.46 GB (23.2%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2728.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0009\t = Validation score   (-pinball_loss)\n",
      "\t4.52s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0009\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.19s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2177.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:38:49,504 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:38:49,504 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.70 GB / 11.46 GB (23.6%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2759.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.1604\t = Validation score   (-pinball_loss)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.1604\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2012.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:38:56,489 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:38:56,489 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.75 GB / 11.46 GB (24.0%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2811.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0576\t = Validation score   (-pinball_loss)\n",
      "\t4.66s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0576\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.61s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2106.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:39:03,168 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:39:03,168 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.75 GB / 11.46 GB (24.0%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2812.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t4.28s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.76s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 782.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:39:11,221 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:39:11,221 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.83 GB / 11.46 GB (24.7%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2895.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0023\t = Validation score   (-pinball_loss)\n",
      "\t4.83s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0023\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.86s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2015.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:39:18,241 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:39:18,241 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.75 GB / 11.46 GB (24.0%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9988215267775304\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2820.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6865, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/2.7 GB\n",
      "\t0.9784\t = Validation score   (f1_macro)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9784\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11295.3 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:39:20,191 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:39:20,191 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.72 GB / 11.46 GB (23.8%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2786.70 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0191\t = Validation score   (-pinball_loss)\n",
      "\t4.8s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0191\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.0s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1305.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:39:28,820 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:39:28,820 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.82 GB / 11.46 GB (24.7%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2877.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.96s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.93s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1413.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:39:35,267 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:39:35,267 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.76 GB / 11.46 GB (24.1%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2821.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/2.7 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 147 due to low memory. Expected memory usage reduced from 30.5% -> 15.0% of available memory...\n",
      "\t0.1267\t = Validation score   (f1_macro)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.1267\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.48s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 15842.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:39:54,034 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:39:54,034 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.84 GB / 11.46 GB (24.8%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2893.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.2s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13255.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:39:55,486 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:39:55,486 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.86 GB / 11.46 GB (25.0%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2921.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.8 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.29s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13286.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:39:57,042 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:39:57,042 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.80 GB / 11.46 GB (24.4%)\n",
      "Disk Space Avail:   96.23 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2870.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.0477\t = Validation score   (-pinball_loss)\n",
      "\t5.0s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.0477\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.03s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2072.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:40:04,435 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:40:04,435 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.83 GB / 11.46 GB (24.7%)\n",
      "Disk Space Avail:   96.22 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2894.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0215\t = Validation score   (-pinball_loss)\n",
      "\t4.96s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0215\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1945.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:40:16,733 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:40:16,733 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.91 GB / 11.46 GB (25.4%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2971.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.2618\t = Validation score   (-pinball_loss)\n",
      "\t4.96s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.2618\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1998.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:40:30,755 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:40:30,755 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.97 GB / 11.46 GB (25.9%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3039.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0006\t = Validation score   (-pinball_loss)\n",
      "\t3.55s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0006\t = Validation score   (-pinball_loss)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2030.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:40:43,718 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:40:43,718 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.98 GB / 11.46 GB (26.0%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3035.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0005\t = Validation score   (-pinball_loss)\n",
      "\t4.17s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0005\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.66s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1982.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:40:57,207 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:40:57,207 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.12 GB / 11.46 GB (27.2%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3190.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.1163\t = Validation score   (-pinball_loss)\n",
      "\t3.81s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.1163\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.6s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1966.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:41:03,860 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:41:03,860 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.07 GB / 11.46 GB (26.8%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3151.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0388\t = Validation score   (-pinball_loss)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0388\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.95s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2002.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:41:10,937 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:41:10,937 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.09 GB / 11.46 GB (27.0%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3161.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t4.13s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.18s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1264.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:41:18,240 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:41:18,240 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.05 GB / 11.46 GB (26.6%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3110.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0015\t = Validation score   (-pinball_loss)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0015\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.96s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2074.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:41:25,377 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:41:25,377 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.09 GB / 11.46 GB (26.9%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9986905853083672\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3155.90 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6864, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/3.1 GB\n",
      "\t0.9868\t = Validation score   (f1_macro)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9868\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.58s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11232.0 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:41:27,271 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:41:27,271 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.01 GB / 11.46 GB (26.3%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3084.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0117\t = Validation score   (-pinball_loss)\n",
      "\t5.01s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0117\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.2s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1495.2 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:41:36,402 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:41:36,402 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.00 GB / 11.46 GB (26.2%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3064.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.95s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1463.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:41:43,010 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:41:43,010 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.95 GB / 11.46 GB (25.7%)\n",
      "Disk Space Avail:   96.24 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3018.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/2.9 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 158 due to low memory. Expected memory usage reduced from 28.37% -> 15.0% of available memory...\n",
      "\t0.1471\t = Validation score   (f1_macro)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.1471\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16499.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: No scaling function was supplied for WrongUnit, defaulting to multiplication by 10.0.\n",
      "  return self._apply(data, error_mask, column)\n",
      "/home/chandlernick/BHT/Research/error-demo/.venv/lib/python3.10/site-packages/tab_err/error_type/_error_type.py:67: UserWarning: self.config.add_delta_value is none, sampling a random delta value uniformly from the range of column: ship_speed.\n",
      "  return self._apply(data, error_mask, column)\n",
      "2026-01-15 16:42:03,160 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "2026-01-15 16:42:03,160 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #1 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/lever_position\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.03 GB / 11.46 GB (26.4%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       lever_position\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3065.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.9 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11073.6 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/lever_position\")\n",
      "2026-01-15 16:42:04,717 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "2026-01-15 16:42:04,717 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #2 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ship_speed\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.93 GB / 11.46 GB (25.6%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       ship_speed\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3008.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.0/2.9 GB\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t1.0\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.38s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11412.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/ship_speed\")\n",
      "2026-01-15 16:42:06,429 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "2026-01-15 16:42:06,429 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #3 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.95 GB / 11.46 GB (25.7%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_shaft_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3018.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-1.1293\t = Validation score   (-pinball_loss)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-1.1293\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.91s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2021.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_shaft_torque\")\n",
      "2026-01-15 16:42:13,390 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "2026-01-15 16:42:13,390 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #4 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.97 GB / 11.46 GB (25.9%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3037.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0191\t = Validation score   (-pinball_loss)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0191\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.79s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2069.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_rate_of_revolutions\")\n",
      "2026-01-15 16:42:20,244 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "2026-01-15 16:42:20,244 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #5 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.04 GB / 11.46 GB (26.6%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_generator_rate_of_revolutions\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3112.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'starboard_propeller_torque', 'hp_turbine_exit_temperature', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.2401\t = Validation score   (-pinball_loss)\n",
      "\t4.84s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.2401\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.86s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1927.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_generator_rate_of_revolutions\")\n",
      "2026-01-15 16:42:27,240 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "2026-01-15 16:42:27,240 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #6 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/starboard_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.04 GB / 11.46 GB (26.5%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       starboard_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3103.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'port_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.0s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.43s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1800.4 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/starboard_propeller_torque\")\n",
      "2026-01-15 16:42:33,627 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "2026-01-15 16:42:33,627 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #7 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/port_propeller_torque\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.04 GB / 11.46 GB (26.6%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       port_propeller_torque\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3112.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0004\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.35s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1988.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/port_propeller_torque\")\n",
      "2026-01-15 16:42:40,090 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "2026-01-15 16:42:40,090 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #8 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.05 GB / 11.46 GB (26.6%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3119.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0893\t = Validation score   (-pinball_loss)\n",
      "\t4.89s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0893\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1928.9 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_temperature\")\n",
      "2026-01-15 16:42:47,323 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "2026-01-15 16:42:47,323 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #9 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.88 GB / 11.46 GB (25.1%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_temperature\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2953.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0344\t = Validation score   (-pinball_loss)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0344\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.66s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2012.7 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_temperature\")\n",
      "2026-01-15 16:42:54,165 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "2026-01-15 16:42:54,165 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #10 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.94 GB / 11.46 GB (25.6%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       hp_turbine_exit_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2984.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t4.47s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.57s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1228.1 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/hp_turbine_exit_pressure\")\n",
      "2026-01-15 16:43:02,118 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "2026-01-15 16:43:02,118 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #11 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.90 GB / 11.46 GB (25.3%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_outlet_air_pressure\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2961.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0013\t = Validation score   (-pinball_loss)\n",
      "\t4.89s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0013\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.91s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2101.5 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_outlet_air_pressure\")\n",
      "2026-01-15 16:43:09,107 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "2026-01-15 16:43:09,107 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #12 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.95 GB / 11.46 GB (25.8%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gas_turbine_exhaust_gas_pressure\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 19 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9985596438392039\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3018.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6863, Val Rows: 763\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.1/2.9 GB\n",
      "\t0.9918\t = Validation score   (f1_macro)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9918\t = Validation score   (f1_macro)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.96s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11340.2 rows/s (763 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gas_turbine_exhaust_gas_pressure\")\n",
      "2026-01-15 16:43:11,317 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "2026-01-15 16:43:11,317 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #13 of 15\n",
      "Ignoring 'problem_type' of given 'predictor_params' since it is already defined.\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/turbine_injecton_control\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       2.91 GB / 11.46 GB (25.4%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       turbine_injecton_control\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2975.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0111\t = Validation score   (-pinball_loss)\n",
      "\t5.0s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0111\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.58s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1074.8 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/turbine_injecton_control\")\n",
      "2026-01-15 16:43:26,276 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "2026-01-15 16:43:26,276 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #14 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/fuel_flow\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.00 GB / 11.46 GB (26.2%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       fuel_flow\n",
      "Problem Type:       quantile\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3049.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.2s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pinball_loss'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0\n",
      "\tWARNING: RandomForestQuantileRegressor are experimental for quantile regression. They may change or be removed without warning in future releases.\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t-0.0001\t = Validation score   (-pinball_loss)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.84s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1535.3 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/fuel_flow\")\n",
      "2026-01-15 16:43:34,611 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "2026-01-15 16:43:34,611 - INFO - conformal_data_cleaning.cleaner.autogluon: Start fitting predictor #15 of 15\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #91~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 15:20:45 UTC 2\n",
      "CPU Count:          8\n",
      "Memory Avail:       3.01 GB / 11.46 GB (26.3%)\n",
      "Disk Space Avail:   96.21 GB / 467.89 GB (20.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\"\n",
      "Train Data Rows:    7637\n",
      "Train Data Columns: 14\n",
      "Label Column:       gt_compressor_decay_state_coefficient\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 51\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3078.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['port_propeller_torque']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['port_propeller_torque']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['lever_position', 'gas_turbine_shaft_torque', 'gas_turbine_rate_of_revolutions', 'gas_generator_rate_of_revolutions', 'starboard_propeller_torque', ...]\n",
      "\t\t('int', [])   :  1 | ['ship_speed']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6873, Val Rows: 764\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFitting with cpus=8, gpus=0, mem=0.2/3.0 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 162 due to low memory. Expected memory usage reduced from 27.77% -> 15.0% of available memory...\n",
      "\t0.1517\t = Validation score   (f1_macro)\n",
      "\t1.93s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.1517\t = Validation score   (f1_macro)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.74s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13441.0 rows/s (764 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/chandlernick/BHT/Research/error-demo/data/AutogluonModels/gt_compressor_decay_state_coefficient\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tab_err.api.high_level import create_errors_with_config\n",
    "\n",
    "error_rates = [0.05, 0.1, 0.25]\n",
    "conf_lvls = [0.9, 0.99, 0.999]\n",
    "\n",
    "cleaned_dfs = {}\n",
    "\n",
    "coverage_results = pd.DataFrame(\n",
    "    columns=[\"Error Rate\", \"Confidence Level\", \"Coverage\"]\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for e_rate in error_rates:\n",
    "    for c_lvl in conf_lvls:\n",
    "        perturbed_df, error_mask, config = create_errors_with_config(\n",
    "            df_test,\n",
    "            error_rate=e_rate,\n",
    "            seed=1,\n",
    "        )\n",
    "\n",
    "        clean_df, clean_mask, coverages = conformal_clean(\n",
    "            perturbed_df,\n",
    "            train_df=df_train,\n",
    "            c_level=c_lvl,\n",
    "        )\n",
    "\n",
    "        for cov in coverages:\n",
    "            rows.append({\n",
    "                \"Error Rate\": e_rate,\n",
    "                \"Confidence Level\": c_lvl,\n",
    "                \"Coverage\": cov,\n",
    "            })\n",
    "\n",
    "coverage_results = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657a334b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>Confidence Level</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.051948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.856305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.895685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.861751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.750314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.693339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.750314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.804357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.687055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Error Rate  Confidence Level  Coverage\n",
       "0          0.05             0.900  0.000000\n",
       "1          0.05             0.900  0.051948\n",
       "2          0.05             0.900  0.856305\n",
       "3          0.05             0.900  0.895685\n",
       "4          0.05             0.900  0.861751\n",
       "..          ...               ...       ...\n",
       "130        0.25             0.999  0.750314\n",
       "131        0.25             0.999  0.693339\n",
       "132        0.25             0.999  0.750314\n",
       "133        0.25             0.999  0.804357\n",
       "134        0.25             0.999  0.687055\n",
       "\n",
       "[135 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92aa5077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "for err, g in coverage_results.groupby(\"Error Rate\"):\n",
    "    plt.plot(g[\"Confidence Level\"], g[\"Coverage\"], label=f\"err={err}\", alpha=0.6)\n",
    "\n",
    "plt.plot([0.8, 1], [0, 1], linestyle=\"--\")  # ideal calibration\n",
    "plt.xlabel(\"Confidence Level\")\n",
    "plt.ylabel(\"Empirical Coverage\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "error-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
